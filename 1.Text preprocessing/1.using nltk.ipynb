{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "050759c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21156cb",
   "metadata": {},
   "source": [
    "# 1.Word tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a955a6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "591e1375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'is', 'a', 'fascinating', 'field', 'of', 'study', '.']\n",
      "['It', 'focuses', 'on', 'the', 'interaction', 'between', 'computers', 'and', 'human', 'language', '.']\n",
      "['NLP', 'techniques', 'are', 'widely', 'used', 'in', 'various', 'applications', 'like', 'chatbots', ',', 'sentiment', 'analysis', ',', 'and', 'machine', 'translation', '.']\n",
      "['Xin', 'chào', ',', 'đây', 'là', 'một', 'ví', 'dụ', 'về', 'xử', 'lý', 'ngôn', 'ngữ', 'tự', 'nhiên', '.']\n"
     ]
    }
   ],
   "source": [
    "sentence1 = \"Natural Language Processing (NLP) is a fascinating field of study.\"\n",
    "sentence2 = \"It focuses on the interaction between computers and human language.\"\n",
    "sentence3 = \"NLP techniques are widely used in various applications like chatbots, sentiment analysis, and machine translation.\"\n",
    "sentence4 = \"Xin chào, đây là một ví dụ về xử lý ngôn ngữ tự nhiên.\"\n",
    "tokens1 = word_tokenize(sentence1)\n",
    "tokens2 = word_tokenize(sentence2)\n",
    "tokens3 = word_tokenize(sentence3)\n",
    "tokens4 = word_tokenize(sentence4)\n",
    "print(tokens1)\n",
    "print(tokens2)\n",
    "print(tokens3)\n",
    "print(tokens4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621a51c0",
   "metadata": {},
   "source": [
    "# 2. Sentence tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5e9ed63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84bbbccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is an example of sentence tokenization.', 'It splits text into individual sentences.', 'NLP is fun!']\n",
      "['Chào bạn!', 'Đây là ví dụ về phân tách câu.', 'Xử lý ngôn ngữ tự nhiên rất thú vị.']\n"
     ]
    }
   ],
   "source": [
    "sentences1 = \"This is an example of sentence tokenization. It splits text into individual sentences.  NLP is fun!\"\n",
    "sentences2 = \"Chào bạn! Đây là ví dụ về phân tách câu. Xử lý ngôn ngữ tự nhiên rất thú vị.\"\n",
    "sent_list1 = sent_tokenize(sentences1)\n",
    "sent_list2 = sent_tokenize(sentences2)\n",
    "print(sent_list1)\n",
    "print(sent_list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d55da3f",
   "metadata": {},
   "source": [
    "# 3.Tree bank Word Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc135391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Have', 'a', 'look', 'at', 'NLTK', \"'s\", 'tokenizers', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "tokens = tokenizer.tokenize(\"Have a look at NLTK's tokenizers.\")\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdffa72",
   "metadata": {},
   "source": [
    "# 4. Regex Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15e709f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Custom', 'rule', 'keep', 'only', 'words', 'numbers', 'drop', 'punctuation']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokens = tokenizer.tokenize(\n",
    "    \"Custom rule: keep only words & numbers, drop punctuation!\")\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc2bd8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Xin', 'chào', 'Đây', 'là', 'ví', 'dụ', 'về', 'phân', 'tách', 'từ', 'sử', 'dụng', 'RegexpTokenizer', 'Sử', 'dụng', 'quy', 'tắc', 'tùy', 'chỉnh', 'để', 'giữ', 'lại', 'chỉ', 'các', 'từ', 'và', 'số', 'loại', 'bỏ', 'dấu', 'câu']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(\"Xin chào! Đây là ví dụ về phân tách từ sử dụng RegexpTokenizer. Sử dụng quy tắc tùy chỉnh để giữ lại chỉ các từ và số, loại bỏ dấu câu!\")\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5fbb14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
